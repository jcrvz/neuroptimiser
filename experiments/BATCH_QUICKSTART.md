# Batch Experiments - Quick Reference

## ğŸ“ Files Created

| File | Purpose |
|------|---------|
| `nengo-neuropti-v7-batch.py` | Modified optimizer (no plots, JSON output) |
| `run_batch_experiments.py` | Main batch runner |
| `analyze_results.py` | Post-processing and visualization |
| `launch_batch.sh` | Quick launcher with confirmation |
| `BATCH_EXPERIMENTS_README.md` | Detailed documentation |

## ğŸš€ Quick Start

### Option 1: Interactive Launch
```bash
./launch_batch.sh
```

### Option 2: Direct Python
```bash
python run_batch_experiments.py
```

### Option 3: Single Experiment
```bash
python nengo-neuropti-v7-batch.py <fid> <instance> <dims> output.json

# Example:
python nengo-neuropti-v7-batch.py 1 1 10 result.json
```

## ğŸ“Š Experiment Configuration

- **Functions**: 1, 2, 8, 10, 15, 17, 20, 21, 24 (9 functions)
- **Instances**: 1-15 (15 instances per function)
- **Dimensions**: 2, 10 (2 dimension settings)
- **Total**: 9 Ã— 15 Ã— 2 = **270 experiments**
- **Time per experiment**: ~20-30 seconds
- **Total time**: ~2-3 hours

## ğŸ“ˆ Results Structure

```
batch_results/
â”œâ”€â”€ result_f01_i01_d02.json       # Individual results
â”œâ”€â”€ result_f01_i01_d10.json
â”œâ”€â”€ ...
â”œâ”€â”€ summary_YYYYMMDD_HHMMSS.csv   # Generated by batch runner
â”œâ”€â”€ statistics_YYYYMMDD_HHMMSS.json
â””â”€â”€ analysis_plots/               # Generated by analyze_results.py
    â”œâ”€â”€ error_distribution_by_dimension.pdf  # Violin plots
    â”œâ”€â”€ error_distribution_by_dimension.png
    â”œâ”€â”€ error_by_function.pdf                # Grouped bar charts
    â”œâ”€â”€ error_by_function.png
    â”œâ”€â”€ operator_usage_by_dimension.pdf      # Stacked bar charts
    â”œâ”€â”€ operator_usage_by_dimension.png
    â”œâ”€â”€ error_vs_operator_usage.pdf          # Scatter with regression
    â”œâ”€â”€ error_vs_operator_usage.png
    â”œâ”€â”€ error_violin_by_function.pdf         # Violin plots
    â”œâ”€â”€ error_violin_by_function.png
    â”œâ”€â”€ performance_heatmap.pdf              # Performance heatmap
    â””â”€â”€ performance_heatmap.png
```

## ğŸ” Data Saved per Experiment

Each JSON file contains:

```json
{
  "configuration": {
    "simulation_time": 20.0,
    "lambda": 50,
    "mu": 25
  },
  "problem": {
    "function_id": 1,
    "instance": 1,
    "dimension": 10
  },
  "performance": {
    "total_evaluations": 1000000,
    "best_fitness": 0.123,
    "optimal_fitness": 0.0,
    "error": 0.123
  },
  "operator_usage": {
    "LF": 150,  // LÃ©vy Flight
    "DM": 200,  // Differential Mutation
    "PS": 300,  // Particle Swarm
    "SP": 350   // Spiral
  },
  "operator_percentages": {...},
  "operator_weights": {...},
  "best_solution": {...},
  "optimal_solution": {...}
}
```

## ğŸ“Š Analysis

After experiments complete:

```bash
python analyze_results.py
```

This generates:
- Summary statistics (printed to console)
- CSV with all results (`analysis_summary.csv`)
- 5 visualization plots in `batch_results/analysis_plots/`

### Manual Analysis with Pandas

```python
import pandas as pd
import json

# Load summary
df = pd.read_csv('batch_results/summary_*.csv')

# Statistics by dimension
print(df.groupby('dimension')['error'].describe())

# Statistics by function
print(df.groupby('function_id')['error'].describe())

# Operator usage vs performance
print(df[['error', 'op_LF_percent', 'op_DM_percent', 
          'op_PS_percent', 'op_SP_percent']].corr())

# Best performing configurations
print(df.nsmallest(10, 'error'))
```

## ğŸ”§ Customization

### Change experiment parameters

Edit `run_batch_experiments.py`:
```python
FUNCTION_IDS = [1, 2, 8, 10, 15, 17, 20, 21, 24]  # Modify this
INSTANCES = list(range(1, 16))                     # Modify this
DIMENSIONS = [2, 10]                               # Modify this
```

### Change optimization parameters

Edit `nengo-neuropti-v7-batch.py`:
```python
SIMULATION_TIME = 20.0  # Increase for more evaluations
LAMBDA = 50             # Population size
MU = 25                 # Memory size
```

## âš¡ Performance Tips

1. **Resume interrupted runs**: The batch runner skips existing results
2. **Parallel execution**: Modify `run_batch_experiments.py` to use `multiprocessing`
3. **Faster testing**: Reduce `SIMULATION_TIME` to 5.0 for quick tests
4. **Memory issues**: Experiments run sequentially by default (no memory accumulation)

## ğŸ“ Typical Workflow

1. **Run experiments**:
   ```bash
   ./launch_batch.sh
   ```

2. **Monitor progress**:
   - Watch console output
   - Check `batch_results/` directory for growing result files

3. **Analyze results**:
   ```bash
   python analyze_results.py
   ```

4. **Load into notebook/script**:
   ```python
   import pandas as pd
   df = pd.read_csv('batch_results/analysis_summary.csv')
   # Your analysis here
   ```

## ğŸ› Troubleshooting

| Issue | Solution |
|-------|----------|
| Import errors | Activate conda environment with nengo, ioh |
| Timeout | Increase timeout in `run_batch_experiments.py` |
| Memory issues | Reduce `LAMBDA` or `SIMULATION_TIME` |
| Missing results | Check error messages in console |
| Slow performance | Normal - each experiment takes ~20-30s |

## ğŸ“š IOHexperimenter Function IDs

- **F1**: Sphere
- **F2**: Ellipsoid Separable
- **F8**: Rosenbrock Original
- **F10**: Ellipsoid Rotated
- **F15**: Rastrigin Separable
- **F17**: Schaffer F7
- **F20**: Schwefel x*sin(x)
- **F21**: Gallagher 101 Peaks
- **F24**: Lunacek bi-Rastrigin

## âœ… Validation

Test with a single quick experiment:
```bash
python nengo-neuropti-v7-batch.py 1 1 2 test.json
cat test.json  # Verify JSON structure
rm test.json   # Clean up
```

## ğŸ“¦ Dependencies

Required packages:
- `nengo` (spiking neural networks)
- `ioh` (IOHexperimenter benchmark functions)
- `numpy`
- `pandas` (for analysis)
- `matplotlib` (for plotting)
- `seaborn` (for plotting)

Install with:
```bash
pip install nengo ioh numpy pandas matplotlib seaborn
```

---

**Questions?** Check `BATCH_EXPERIMENTS_README.md` for detailed documentation.

